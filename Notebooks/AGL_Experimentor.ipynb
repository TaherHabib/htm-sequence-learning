{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/thabib/Documents/Personal/Master_Thesis/1_HTMImplementation'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive\n",
    "\n",
    "from rebergrammar_generator import *\n",
    "from experimentor import Experimentor\n",
    "from ufuncs import full_pickle, unpickle, compress_pickle, decompress_pickle\n",
    "\n",
    "os.getcwd()\n",
    "# np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiment (SRG/ERG learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param Settings (NOTE: Define `trial` carefully, for consistent saving of data later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network params\n",
    "M = 8\n",
    "N = 175\n",
    "k = 25\n",
    "\n",
    "perm_decrement = 0.01 # p-\n",
    "perm_increment = 2*perm_decrement # p+\n",
    "perm_decay = 0.15*perm_decrement # p--\n",
    "perm_boost = 0.1*perm_decrement # p++\n",
    "\n",
    "# Cell params\n",
    "dendrites_percell = 32\n",
    "connSynapses_perdend = 32 # not functional, at the moment\n",
    "nmda_threshold = 20\n",
    "permanence_threshold = 0.40\n",
    "init_permanence = 0.25\n",
    "activity_horizon = None\n",
    "activity_threshold = None\n",
    "\n",
    "# Task params\n",
    "do_ERG = False\n",
    "nof_strings = 2000\n",
    "\n",
    "trial = 'trial_2_'\n",
    "\n",
    "\n",
    "dict_params = {\n",
    "    'M': M,\n",
    "    'N': N,\n",
    "    'k': k,\n",
    "    'dendrites_percell': dendrites_percell,\n",
    "    'connSynapses_perdend': connSynapses_perdend,\n",
    "    'nmda_th': nmda_threshold,\n",
    "    'perm_th': permanence_threshold,\n",
    "    'perm_init': init_permanence,\n",
    "    'activity_horizon': activity_horizon,\n",
    "    'activity_th': activity_threshold,\n",
    "    'perm_decrement': perm_decrement,\n",
    "    'perm_increment': perm_increment,\n",
    "    'perm_decay': perm_decay,\n",
    "    'perm_boost': perm_boost,\n",
    "    'do_ERG': do_ERG,\n",
    "    'nof_strings': nof_strings\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Initializer and Launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "exp = Experimentor(M=M, N=N, k=k, \n",
    "                   n_dendrites=dendrites_percell, \n",
    "                   n_synapses=connSynapses_perdend, \n",
    "                   nmda_th=nmda_threshold, \n",
    "                   perm_th=permanence_threshold, \n",
    "                   perm_init=init_permanence, \n",
    "                   perm_decrement=perm_decrement, \n",
    "                   perm_increment=perm_increment, \n",
    "                   perm_decay=perm_decay, \n",
    "                   perm_boost=perm_boost,\n",
    "                   activity_horizon=activity_horizon, \n",
    "                   activity_th=activity_threshold,\n",
    "                   do_ERG=do_ERG, \n",
    "                   nof_strings=nof_strings)\n",
    "\n",
    "\n",
    "dict_results = exp.run_experiment()\n",
    "\n",
    "print(time.time()-start)\n",
    "\n",
    "# 3606 secs for 1000 strings\n",
    "# 19374 secs for 5000 strings\n",
    "# 7845 secs for 2000 strings\n",
    "\n",
    "# sys.getsizeof(dict_results['results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_ERG:\n",
    "    exp_filename = trial+'ERG_'+str(nof_strings)\n",
    "else:\n",
    "    exp_filename = trial+'SRG_'+str(nof_strings)\n",
    "\n",
    "\n",
    "# USING PICKLE\n",
    "filename = exp_filename+'_chars_to_minicols'\n",
    "full_pickle(filename, dict_results['chars_to_minicols'])\n",
    "filename = exp_filename+'_in_strings_oh'\n",
    "full_pickle(filename, dict_results['in_strings_onehot'])\n",
    "filename = exp_filename+'_out_strings_oh'\n",
    "full_pickle(filename, dict_results['out_strings_onehot'])\n",
    "filename = exp_filename+'_exp_params'\n",
    "full_pickle(filename, dict_params)\n",
    "\n",
    "filename = exp_filename+'_results'\n",
    "compress_pickle(filename, dict_results['results'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with Reber Grammar Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = Reber_Grammar(175, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>T</th>\n",
       "      <th>S</th>\n",
       "      <th>X</th>\n",
       "      <th>P</th>\n",
       "      <th>V</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>59</td>\n",
       "      <td>61</td>\n",
       "      <td>47</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>69</td>\n",
       "      <td>54</td>\n",
       "      <td>88</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>58</td>\n",
       "      <td>91</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>72</td>\n",
       "      <td>89</td>\n",
       "      <td>79</td>\n",
       "      <td>66</td>\n",
       "      <td>98</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52</td>\n",
       "      <td>73</td>\n",
       "      <td>92</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "      <td>111</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "      <td>101</td>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>117</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>67</td>\n",
       "      <td>84</td>\n",
       "      <td>106</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>127</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68</td>\n",
       "      <td>108</td>\n",
       "      <td>121</td>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>71</td>\n",
       "      <td>113</td>\n",
       "      <td>123</td>\n",
       "      <td>104</td>\n",
       "      <td>115</td>\n",
       "      <td>136</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>86</td>\n",
       "      <td>119</td>\n",
       "      <td>133</td>\n",
       "      <td>107</td>\n",
       "      <td>116</td>\n",
       "      <td>141</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90</td>\n",
       "      <td>145</td>\n",
       "      <td>138</td>\n",
       "      <td>109</td>\n",
       "      <td>120</td>\n",
       "      <td>144</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>102</td>\n",
       "      <td>146</td>\n",
       "      <td>139</td>\n",
       "      <td>114</td>\n",
       "      <td>122</td>\n",
       "      <td>155</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>103</td>\n",
       "      <td>151</td>\n",
       "      <td>140</td>\n",
       "      <td>118</td>\n",
       "      <td>125</td>\n",
       "      <td>162</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>105</td>\n",
       "      <td>153</td>\n",
       "      <td>142</td>\n",
       "      <td>124</td>\n",
       "      <td>128</td>\n",
       "      <td>163</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>110</td>\n",
       "      <td>154</td>\n",
       "      <td>147</td>\n",
       "      <td>129</td>\n",
       "      <td>132</td>\n",
       "      <td>168</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>126</td>\n",
       "      <td>158</td>\n",
       "      <td>149</td>\n",
       "      <td>148</td>\n",
       "      <td>137</td>\n",
       "      <td>169</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>156</td>\n",
       "      <td>159</td>\n",
       "      <td>161</td>\n",
       "      <td>152</td>\n",
       "      <td>160</td>\n",
       "      <td>171</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>157</td>\n",
       "      <td>172</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A    T    S    X    P    V    Z\n",
       "0     5    0    9    2    1   11    3\n",
       "1     8   21   14   13    7   19    4\n",
       "2    17   24   18   16   12   22    6\n",
       "3    31   32   27   23   25   26   10\n",
       "4    33   40   30   37   34   35   15\n",
       "5    38   53   51   44   36   41   20\n",
       "6    42   59   61   47   39   46   28\n",
       "7    45   63   70   56   43   57   29\n",
       "8    48   64   77   69   54   88   55\n",
       "9    49   65   81   78   58   91   60\n",
       "10   50   72   89   79   66   98   75\n",
       "11   52   73   92   83   82  111   76\n",
       "12   62   74  101   87   85  117   80\n",
       "13   67   84  106   96   95  127   93\n",
       "14   68  108  121   99   97  135   94\n",
       "15   71  113  123  104  115  136  100\n",
       "16   86  119  133  107  116  141  112\n",
       "17   90  145  138  109  120  144  130\n",
       "18  102  146  139  114  122  155  131\n",
       "19  103  151  140  118  125  162  134\n",
       "20  105  153  142  124  128  163  143\n",
       "21  110  154  147  129  132  168  150\n",
       "22  126  158  149  148  137  169  165\n",
       "23  156  159  161  152  160  171  167\n",
       "24  157  172  164  166  173  174  170"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.df_CharsToMinicols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A', 'T', 'X', 'X', 'V', 'T', 'P', 'V', 'Z'],\n",
       " [('T', 'P'),\n",
       "  ('S', 'X'),\n",
       "  ('V', 'X'),\n",
       "  'V',\n",
       "  ('T', 'P', 'S'),\n",
       "  ('T', 'P', 'S'),\n",
       "  ('V', 'X'),\n",
       "  'Z'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.generateSequences()\n",
    "# ATSXPVZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 1., 0., 1., 0.]),\n",
       "  array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1.]),\n",
       "  array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         1., 0., 1., 0., 0.]),\n",
       "  array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1.]),\n",
       "  array([0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0.]),\n",
       "  array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         1., 0., 1., 0., 0.]),\n",
       "  array([0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.])],\n",
       " [array([1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "         1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "         0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1.]),\n",
       "  array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         1., 0., 1., 0., 0.]),\n",
       "  array([1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "         1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "         0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "         0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "         0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1.]),\n",
       "  array([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "         1., 0., 1., 0., 0.]),\n",
       "  array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         1., 0., 1., 0., 0.]),\n",
       "  array([1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "         1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "         0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "         0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "         0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1.]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "         1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.])])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.get_one_srg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rg_inout = rg.get_n_srg(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rg_inout[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_in_strings = [rg_inout[i][0] for i in range(5)]\n",
    "list_out_strings = [rg_inout[i][1] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATXXVTPXVSZ', 'APVPVZ', 'APVTSZ', 'APVPXVSZ', 'ATXXVPXVPVZ']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_strings_alpha = []\n",
    "for string_oh in list_in_strings:\n",
    "    string_alpha = rg.OnehotToWord(string_oh)\n",
    "    in_strings_alpha.append(string_alpha)\n",
    "    \n",
    "in_strings_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_in_strings[3][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.in_grammar(rg.OnehotToWord(rg.get_n_srg(5)[3][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = rg.get_n_srg(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rg.hist_len_rg(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0\n",
    "for i in len_erg_examples:\n",
    "    if i>20:\n",
    "        c+=1\n",
    "c    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "a = [(1,2),(2,2),(3,1)]\n",
    "b = [a[i][0] for i in range(len(a))]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::ROUGH::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with feathers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>H</th>\n",
       "      <th>string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[16, 0]</td>\n",
       "      <td>Taher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9, 0, 24]</td>\n",
       "      <td>11</td>\n",
       "      <td>hussain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            T        H   string\n",
       "0           3  [16, 0]    Taher\n",
       "1  [9, 0, 24]       11  hussain"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "\n",
    "arr = np.random.randn(10)\n",
    "dic = {'T': [3,[9,0,24]], 'H': [[16,0],11], 'string': ['Taher', 'hussain']}\n",
    "df = pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "('cannot mix list and non-list, non-null values', 'Conversion failed for column T with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0c992c881c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tahresearch/lib/python3.8/site-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tahresearch/lib/python3.8/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnthreads\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         arrays = [convert_column(c, f)\n\u001b[0m\u001b[1;32m    555\u001b[0m                   for c, f in zip(columns_to_convert, convert_fields)]\n\u001b[1;32m    556\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tahresearch/lib/python3.8/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnthreads\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         arrays = [convert_column(c, f)\n\u001b[0m\u001b[1;32m    555\u001b[0m                   for c, f in zip(columns_to_convert, convert_fields)]\n\u001b[1;32m    556\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tahresearch/lib/python3.8/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mconvert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    544\u001b[0m             e.args += (\"Conversion failed for column {0!s} with type {1!s}\"\n\u001b[1;32m    545\u001b[0m                        .format(col.name, col.dtype),)\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfield_nullable\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnull_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             raise ValueError(\"Field {} was non-nullable but pandas column \"\n",
      "\u001b[0;32m~/anaconda3/envs/tahresearch/lib/python3.8/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mconvert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         except (pa.ArrowInvalid,\n\u001b[1;32m    542\u001b[0m                 \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArrowNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tahresearch/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tahresearch/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tahresearch/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: ('cannot mix list and non-list, non-null values', 'Conversion failed for column T with type object')"
     ]
    }
   ],
   "source": [
    "table = pa.Table.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with hdf5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>H</th>\n",
       "      <th>string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[16, 0]</td>\n",
       "      <td>Taher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9, 0, 24]</td>\n",
       "      <td>11</td>\n",
       "      <td>hussain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            T        H   string\n",
       "0           3  [16, 0]    Taher\n",
       "1  [9, 0, 24]       11  hussain"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast \n",
    "\n",
    "arr = np.random.randn(10)\n",
    "dic = {'T': [3,[9,0,24]], 'H': [[16,0],11], 'string': ['Taher', 'hussain']}\n",
    "#df = pd.DataFrame(columns=['Name', 'Birth'])\n",
    "df = pd.DataFrame(dic)\n",
    "#display(np.array(df))\n",
    "#dic = np.array(dic).reshape(1,-1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, list([16, 0]), 'Taher'],\n",
       "       [list([9, 0, 24]), 11, 'hussain']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array(df))\n",
    "df.columns = dic.keys()\n",
    "np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('SRG_100str.hdf5', 'a') as f:\n",
    "    g1 = f.create_group('trial_4')\n",
    "    g1.create_dataset(\"df_results\", data=np.array(df), dtype=h5py.string_dtype(encoding='utf-8'), \n",
    "                      compression=\"gzip\", compression_opts=5)\n",
    "    g1.create_dataset(\"dict_results\", data=dic, dtype=h5py.string_dtype(encoding='utf-8'))\n",
    "    g1.create_dataset(\"numpy_array\", data=arr, \n",
    "                      compression=\"gzip\", compression_opts=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('SRG_100str.hdf5', 'r') as f:\n",
    "    \n",
    "    groups = list(f.keys())\n",
    "    \n",
    "    df_ = f[str(groups[2])+'/df_results'][()]\n",
    "    dic_ = f[str(groups[2])+'/dict_results'][()]\n",
    "    arr_ = f[str(groups[2])+'/numpy_array'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['3', '[16, 0]', 'Taher'],\n",
       "       ['[9, 0, 24]', '11', 'hussain']], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"{'T': [3, [9, 0, 24]], 'H': [[16, 0], 11], 'string': ['Taher', 'hussain']}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.39903571, -1.13637657, -0.31234864, -0.46016904,  0.75840975,\n",
       "        0.83245533,  0.05848878,  0.20081061,  0.66599588, -0.10947545])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_)\n",
    "display(dic_)\n",
    "display(arr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tah</th>\n",
       "      <th>Hs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Taher</th>\n",
       "      <td>3</td>\n",
       "      <td>[16, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hussain</th>\n",
       "      <td>[9, 0, 24]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Tah       Hs\n",
       "string                      \n",
       "Taher             3  [16, 0]\n",
       "hussain  [9, 0, 24]       11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'T': [3, [9, 0, 24]], 'H': [[16, 0], 11], 'string': ['Taher', 'hussain']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.39903571, -1.13637657, -0.31234864, -0.46016904,  0.75840975,\n",
       "        0.83245533,  0.05848878,  0.20081061,  0.66599588, -0.10947545])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ = pd.DataFrame(df_)\n",
    "df_.columns = ['Tah', 'Hs', 'string']\n",
    "df_.set_index('string', inplace=True)\n",
    "display(df_)\n",
    "display(ast.literal_eval(dic_))\n",
    "display(arr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thabib/anaconda3/envs/tahresearch/lib/python3.8/site-packages/pandas/util/__init__.py:12: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['fQsDh8piZM', 'GYL9hNuiRt', 'EpxSj4EbeZ', '6IYiKOSa3Y',\n",
       "       'x2mEbH3JMd'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.util.testing.rands_array(10, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Probability for a False Match of SDRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.141747382571475e-20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import comb as ncr\n",
    "    \n",
    "def false_match_prob(a,n,s,th):\n",
    "    summ = 0\n",
    "    for i in range(th, s+1):\n",
    "        summ += ncr(s,i, exact=True)*ncr(n-s,a-i, exact=True)\n",
    "    \n",
    "    prob = summ/ncr(n,a, exact=True)\n",
    "    return prob\n",
    "\n",
    "a = 25 # value of 'k'\n",
    "n = 1400 # total cells in network\n",
    "s = 100 # number of connected synapses on a dendritic segment\n",
    "th = 20  # NMDA threshold \n",
    "        \n",
    "false_match_prob(a,n,s,th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars='TSXPV#'\n",
    "emb_chars = 'TP'\n",
    "\n",
    "graph = [[(1,5),('T','P')] , [(1,2),('S','X')], \\\n",
    "           [(3,5),('V','X')], [(6,),('#')], \\\n",
    "           [(4,2,3),('T','P','S')], [(4,),('V')] ]\n",
    "\n",
    "\n",
    "# TO GENERATE SEQUENCES OF SRG\n",
    "def generateSequences(minLength=5):\n",
    "    \"\"\"\n",
    "    Returns a tuple with\n",
    "    first entry: as array of chars generated from SRG\n",
    "    second entry: as array of next possible transitions from each char in the first entry\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        node = 0\n",
    "        inchars = []\n",
    "        outchars = []    \n",
    "        while node != 6:\n",
    "            transitions = graph[node]\n",
    "            i = np.random.randint(0, len(transitions[0]))\n",
    "            inchars.append(transitions[1][i])\n",
    "            outchars.append(transitions[1])\n",
    "            node = transitions[0][i]\n",
    "        if len(inchars) > minLength:  \n",
    "            return inchars, outchars\n",
    "        \n",
    "        \n",
    "# TO GENERATE ONE-HOT ENCODINGS OF THE OUTPUT ARRAYS OF 'generateSequences()' function\n",
    "def get_one_srg(minLength=5):\n",
    "    inchars, outchars = generateSequences(minLength)\n",
    "    inseq = []\n",
    "    outseq= []\n",
    "    for i,o in zip(inchars, outchars): \n",
    "        inpt = np.zeros(6)\n",
    "        inpt[chars.find(i)] = 1.     \n",
    "        outpt = np.zeros(6)\n",
    "        for oo in o:\n",
    "            outpt[chars.find(oo)] = 1.\n",
    "        inseq.append(inpt)\n",
    "        outseq.append(outpt)\n",
    "    return inseq, outseq\n",
    "\n",
    "\n",
    "# TO CONVERT BACK INTO SYMBOLS FROM THE ONE-HOT ENCODINGS\n",
    "def OnehotToWord(sequence):\n",
    "    \"\"\"\n",
    "    converts a sequence (one-hot) in a reber string\n",
    "    \"\"\"\n",
    "    reberString = ''\n",
    "    for s in sequence:\n",
    "        index = np.where(s==1.0)[0][0]\n",
    "        reberString += chars[index]\n",
    "    reberString+='#'\n",
    "    return reberString\n",
    "\n",
    "\n",
    "def get_n_srg(n, minLength=5):\n",
    "    examples = []\n",
    "    for i in range(n):\n",
    "        examples.append(get_one_srg(minLength))\n",
    "    return examples\n",
    "\n",
    "\n",
    "\n",
    "# ____________________________________For ERG strings__________________________________________#\n",
    "\n",
    "\n",
    "def get_char_onehot(char):\n",
    "    char_oh = np.zeros(6)\n",
    "    if chars.find(char) == -1:\n",
    "        print('Character NOT in Grammar')\n",
    "        return\n",
    "    else:\n",
    "        char_oh[chars.find(char)] = 1.\n",
    "    return char_oh \n",
    "\n",
    "\n",
    "def get_one_erg(minLength=5):\n",
    "    \n",
    "    simple_in, simple_out = get_one_srg()\n",
    "    emb_in = simple_in[:]\n",
    "    emb_out = simple_out[:]\n",
    "    \n",
    "    emb_char = emb_chars[np.random.randint(0, len(emb_chars))]\n",
    "    emb_char_oh = get_char_onehot(emb_char)\n",
    "    \n",
    "    emb_in[1:1] = [emb_char_oh]\n",
    "    emb_in.insert(len(emb_in), emb_char_oh)\n",
    "    print('Embedded INPUT string:', OnehotToWord(emb_in))\n",
    "    \n",
    "    emb_out[1:1] = [simple_out[0]]\n",
    "    emb_out.insert(len(emb_out)-1, get_char_onehot(emb_char))\n",
    "\n",
    "    return emb_in, emb_out\n",
    "\n",
    "\n",
    "def get_n_erg(n, minLength=5):\n",
    "    examples = []\n",
    "    for i in range(n):\n",
    "        examples.append(get_one_erg(minLength))\n",
    "    return examples\n",
    "\n",
    "\n",
    "def in_grammar(word):\n",
    "    node = 0    \n",
    "    for c in word[1:]:\n",
    "        transitions = graph[node]\n",
    "        try:\n",
    "            node = transitions[0][transitions[1].index(c)]\n",
    "        except ValueError: # using exceptions for flow control in python is common\n",
    "            return False\n",
    "    return True        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq, out_seq = get_one_embedded_example(minLength=5)\n",
    "\n",
    "print('Input sequence starting at char index 0 until the second to the last:\\n')\n",
    "print(in_seq)\n",
    "print('-----------------------------------')\n",
    "print('Input sequence as character:')\n",
    "print(sequenceToWord(in_seq))\n",
    "print('-----------------------------------')\n",
    "print('Target sequence starting at char index 1 until the last')\n",
    "print(sequenceToWord(out_seq))\n",
    "print('-----------------------------------')\n",
    "print('Validate a string:')\n",
    "### Append 'E' to input sequence as char at last index is ommited\n",
    "print(in_grammar(sequenceToWord(in_seq)+'E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chars)\n",
    "\n",
    "simple_in, simple_out = get_one_example()\n",
    "print('\\nSimple INPUT string (one-hot):', simple_in)\n",
    "# print(o)\n",
    "\n",
    "emb_char = emb_chars[np.random.randint(0, len(emb_chars))]\n",
    "print('\\nThis is embedded char:', emb_char)\n",
    "\n",
    "oh_emb_char = get_char_one_hot(emb_char)\n",
    "# print('\\nThis is embedded chars one-hot encoding:', oh_emb_char)\n",
    "\n",
    "emb_in = simple_in[:]\n",
    "# print('\\nString before embedding:', emb_in)\n",
    "emb_in[1:1] = [oh_emb_char]\n",
    "# print('\\nString after front embedding:', emb_in)\n",
    "emb_in.insert(len(emb_in), oh_emb_char)\n",
    "# print('\\nString after end embedding:', emb_in)\n",
    "print('\\nEmbedded INPUT string:', sequenceToWord(emb_in))\n",
    "\n",
    "print('\\n\\n\\n Simple OUTPUT string (one-hot):', simple_out)\n",
    "print('\\n Length of Simple OUTPUT string: ', len(simple_out))\n",
    "emb_out = simple_out[:]\n",
    "emb_out[1:1] = [simple_out[0]]\n",
    "emb_out.insert(len(emb_out)-1, simple_out[0])\n",
    "print('\\nEmbedded OUTPUT string (one-hot):', emb_out)\n",
    "print('\\n Length of Embedded OUTPUT string: ', len(emb_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=('string', 'states', 'preds'))\n",
    "df.loc[0] = ['Taher', np.zeros([3,3]), np.array([])]\n",
    "df.loc[1] = ['Taher_', np.zeros([2,2]), np.array([])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Taher\n",
       "1    Taher_\n",
       "Name: string, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rebergrammar_generator import *\n",
    "from experimentor import Experimentor\n",
    "\n",
    "# Network params\n",
    "M = 8\n",
    "N = 175\n",
    "k = 25\n",
    "\n",
    "perm_decrement = 0.05 # p-\n",
    "perm_increment = 2*perm_decrement # p+\n",
    "perm_decay = 0.2*perm_decrement # p--\n",
    "perm_boost = 0.1*perm_decrement # p++\n",
    "\n",
    "# Cell params\n",
    "dendrites_percell = 32\n",
    "connSynapses_perdend = 32 # not functional, at the moment\n",
    "nmda_threshold = 20\n",
    "permanence_threshold = 0.40\n",
    "init_permanence = 0.25\n",
    "activity_horizon = None\n",
    "activity_threshold = None\n",
    "\n",
    "# Task params\n",
    "do_ERG = False\n",
    "nof_strings = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experimentor(M=M, N=N, k=k, n_dendrites=dendrites_percell, n_synapses=connSynapses_perdend, \n",
    "                   nmda_th=nmda_threshold, perm_th=permanence_threshold, perm_init=init_permanence, \n",
    "                   perm_decrement=perm_decrement, perm_increment=perm_increment, \n",
    "                   perm_decay=perm_decay, perm_boost=perm_boost,\n",
    "                   activity_horizon=activity_horizon, activity_th=activity_threshold,\n",
    "                   do_ERG=do_ERG, nof_strings=nof_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(exp.in_strings_alpha))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
